---
title: Model Notation
header-includes: \usepackage{color}
output:
  html_document: default
  pdf_document:
    fig_caption: no
---

<style>
table, th, td { text-align:right; }
th, td {padding: 10px;}
</style>

```{r, echo=FALSE, warning=FALSE, message=FALSE}
whichcomp <- strsplit(getwd(),"/")[[1]][3]
load(paste0("c:/users/", whichcomp, "/Dropbox/teaching/Resma3/Resma3.RData"))
library(knitr)
opts_chunk$set(fig.width=6, fig.align = "center", 
      out.width = "70%", warning=FALSE, message=FALSE)
library(ggplot2)
library(grid)
```
`r hl()$basefontsize()`

A number of R routines (for example boxplot and lm) use the *model* notation *y~x*, which you should read as *y modeled as a function of x*. So for example if we want to find the least squares regression model of y on x we use

```{r eval=FALSE}
lm(y ~ x)
```

In standard math notation that means fitting an equation of the form

$$
Y = \beta_0 + \beta_1 x + \epsilon
$$
Sometimes one wants to fit a no-intercept model:

$$
Y = \beta_1 x + \epsilon
$$
and this is done with

```{r eval=FALSE}
lm(y ~ x - 1)
```

If there are two predictors you can 

-  fit an *addititive* model of the form
$$
Y = \beta_0 + \beta_1 x + \beta_2 z + \epsilon
$$

with

```{r eval=FALSE}
lm(y ~ x + z)
```

-  fit a model with an *interaction* term 

$$
Y = \beta_0 + \beta_1 x + \beta_2 z + \beta_3 x \times z + \epsilon
$$

with

```{r eval=FALSE}
lm(y ~ x * z)
```

`r hl()$vspace()`

In the case of three (or more predictors) there are all sorts of possibilities:

-  model without interactions

$$
Y_i = \beta_0 + \sum_{i=1}^n \beta_i x_i + \epsilon
$$

```{r eval=FALSE} 
lm(y ~ x1 + x2 + x3)
```

-  model with all interactions

$$
Y_i = \beta_0 + \sum_{i=1}^n \beta_i x_i +
\sum_{i,j=1}^n \beta_{ij} x_i x_j + \\
+ \text{ ... } + \\
\beta_{1..n}x_1 \times .. \times x_n + \epsilon
$$

```{r eval=FALSE} 
lm(y ~ (x1 + x2 + x3)^3 )
```

-  model with all pairwise interactions

$$
Y_i = \beta_0 + \sum_{i=1}^n \beta_i x_i + 
\sum_{i,j=1}^n \beta_{ij} x_i x_j  + \epsilon
$$

```{r eval=FALSE} 
lm(y ~ (x1 + x2 + x3)^2 )
```

these model descriptions are not unique, for example the last one is equivalent to

```{r eval=FALSE} 
lm(y ~ x1 * x2 * x3 - x1:x2:x3)
```

Sometime we want * to indicate actual multiplication and not interaction. This can be done with

```{r eval=FALSE} 
lm(y ~ x1 + x2 + I(x1*x2))
```

Another useful one is ., which stands for *all +'s*, so say (y, x1, x2, x3) are the columns of a dataframe df, then

```{r eval=FALSE} 
lm(y ~ x1 + x2 + x3, data=df )
```

is the same as

```{r eval=FALSE} 
lm(y ~ ., data=df )
```

and

```{r eval=FALSE} 
lm(y ~ .*x3, data=df )
```

is the same as

```{r eval=FALSE} 
lm(y ~ x1 + x2 + x3 + x1*x3 +x2*x3)
```

`r hl()$vspace()`

if there are more than a few predictors it is usally easier to generate a matrix of predictors:

```{r eval=FALSE}
X <- cbind(x1, x2, x3, x4)
lm(y ~ X)
```


###Case Study

we have a list of prices and other information on houses in Albuquerque, New Mexico:

```{r}
head(albuquerquehouseprice)
```

-  additive model, all four predictors:

```{r}
attach(albuquerquehouseprice)
summary(lm(Price ~ Sqfeet + Feature + Corner + Tax))
```

- additive model, Sqfeet and Features

```{r}
summary(lm(Price ~ Sqfeet + Feature))
```

- model with interaction, Sqfeet and Features

```{r}
summary(lm(Price ~ Sqfeet * Feature))
```

- model with pairwise interactions:

```{r}
summary(lm(Price ~ (Sqfeet + Feature + Corner +  Tax)^2))
```

- model with all possible terms:

```{r}
summary(lm(Price ~ (Sqfeet + Feature + Corner +  Tax)^4))
```


