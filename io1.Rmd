---
header-includes: \usepackage{color}
output:
  html_document: default
  pdf_document:
    fig_caption: no
---
<style>
table, th, td { text-align:right; }
th, td {padding: 10px;}
</style>

```{r, echo=FALSE, warning=FALSE, message=FALSE}
whichcomp <- strsplit(getwd(),"/")[[1]][3]
load(paste0("c:/users/", whichcomp, "/Dropbox/Resma3/Resma3.RData"))
library(knitr)
opts_chunk$set(fig.width=6, fig.align = "center", 
      out.width = "70%", warning=FALSE, message=FALSE)
library(ggplot2)
library(grid)
```
`r hl()$basefontsize()`

#Input/Output Part 2

There are a number of packages that help with data I/O. Some are specialized for certain data types, others are more general

##rio

One of my favorites is *rio*. An introduction can be found at [https://cran.r-project.org/web/packages/rio/vignettes/rio.html](https://cran.r-project.org/web/packages/rio/vignettes/rio.html). The list of supported file formats is quite impressive! You use the import function to import data and the export function to export. The routine uses the extension to figure out the file format. So say you have a file called mytestdata.csv in a folder called c:/tmpdata, just run

```{r}
B <- 2*1e6
x <- round(rnorm(B), 3)
y <- round(rnorm(B), 3)
z <- sample(letters[1:5], size=B, replace=TRUE)
xyz <- data.frame(x, y, z)
head(xyz, 3)
dir.create("c:/tmpdata")
library(rio)
export(xyz, "c:/tmpdata/mytestdata.csv")
detach(2)
rm(xyz)
```

```{r}
library(rio)
head(import("c:/tmpdata/mytestdata.csv"), 3)
```

###Minitab to R

rio has the ability to read Minitab files. Unfortunately they have to be in the portable format, and Minitab stopped useing that some vversuins ago. So the easiest thing to do is save files a in Minitab as .csv.
 
 
##readr

This package is specific to rectangular data, such as data from an Excel spreadsheet. It's advantage is it's speed:

```{r}
library(readr)
tm <- proc.time()
head(import("c:/tmpdata/mytestdata.csv"), 2)
proc.time()-tm
tm <- proc.time()
head(read_csv("c:/tmpdata/mytestdata.csv"), 2)
proc.time()-tm
```

**Note** that the data is in the form of a *tibble*. This is a  special kind of data frame which we will talk about later.

**Note** the corresponding base R routine was called read.csv

##data.table

Similar to read.table but faster and more convenient. the command is called *fread*:

```{r}
library(data.table)
tm <- proc.time()
head(fread("c:/tmpdata/mytestdata.csv"), 2)
proc.time()-tm
```

This command is what I would recommend if you deal with a Big Data. These days we classify data as follows:

-  big data (a few hundred thousand rows, about 20 MB)  
-  Big Data (5 million rows, about 1GB)  
-  Bigger Data (over 100 million rows, over 10GB)

In the case of Bigger Data you can no longer have all of it in memory, but it becomes necessary to use a hard drive as memory. A useful package for that is *bigmemory*.